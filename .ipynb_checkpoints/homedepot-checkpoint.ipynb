{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"files/train.csv\", encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(\"files/test.csv\", encoding=\"ISO-8859-1\")\n",
    "descriptions = pd.read_csv(\"files/product_descriptions.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "df = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df = pd.merge(df, descriptions, how='left', on='product_uid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_words(str1, str2):\n",
    "    word_count = 0\n",
    "    for word in str1.split():\n",
    "        if word in str2:\n",
    "            word_count += 1\n",
    "    return word_count\n",
    "\n",
    "df[\"word_in_title\"]         = df.apply(lambda row: common_words(row[\"search_term\"], row[\"product_title\"]), axis=1)\n",
    "df[\"word_in_description\"]   = df.apply(lambda row: common_words(row[\"search_term\"], row[\"product_description\"]), axis=1)\n",
    "df[\"query_in_title\"]        = df.apply(lambda row: 1 if row[\"search_term\"] in row[\"product_title\"] else 0, axis=1)\n",
    "df[\"query_in_description\"]  = df.apply(lambda row: 1 if row[\"search_term\"] in row[\"product_description\"] else 0, axis=1)\n",
    "df['length_of_query']       = df['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "train = df.iloc[:num_train]\n",
    "test = df.iloc[num_train:]\n",
    "\n",
    "predictors = [\"word_in_description\", \"word_in_title\", \"query_in_title\", \"query_in_description\", \"length_of_query\"]\n",
    "\n",
    "X_train = train[predictors]\n",
    "Y_train = train[\"relevance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_regression, k=2)\n",
    "selector.fit(X_train, Y_train)\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = selector.pvalues_\n",
    "\n",
    "# Plot the scores.\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584286907608\n",
      "0.520823873452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X_train, Y_train, cv=10, scoring='mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores.mean())\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "scores = cross_val_score(rf, X_train, Y_train, cv=10, scoring='mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(rmse_scores.mean())\n",
    "\n",
    "#TODO: cross validate to find right algorithm. Run grid search to pick optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = knn.predict(test[predictors].values)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": test[\"id\"],\n",
    "        \"relevance\": predictions\n",
    "    }).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
